{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_iCrqcHw2d2"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets\n",
        "!pip install -q loralib\n",
        "!pip install -q sentencepiece\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q accelerate\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q git+https://github.com/huggingface/peft.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zTQ1GAu7xffY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import bitsandbytes as bnb\n",
        "from datasets import load_dataset\n",
        "import transformers"
      ],
      "metadata": {
        "id": "JrK0rIPlxjAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
        "from peft import (\n",
        "    prepare_model_for_int8_training,\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        ")"
      ],
      "metadata": {
        "id": "Td_OUflSxqlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MICRO_BATCH_SIZE = 4 \n",
        "BATCH_SIZE = 128\n",
        "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
        "EPOCHS = 3 \n",
        "LEARNING_RATE = 3e-4\n",
        "CUTOFF_LEN = 512\n",
        "LORA_R = 8\n",
        "LORA_ALPHA = 16\n",
        "LORA_DROPOUT = 0.05\n",
        "VAL_SET_SIZE = 2000\n",
        "TARGET_MODULES = [\n",
        "    \"q_proj\",\n",
        "    \"v_proj\",\n",
        "]\n",
        "DATASET_NAME = \"user/alpaca-data-pt-br\""
      ],
      "metadata": {
        "id": "VHhIh65-xy1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    \"decapoda-research/llama-7b-hf\",\n",
        "    load_in_8bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\n",
        "    \"decapoda-research/llama-7b-hf\", add_eos_token=True\n",
        ")"
      ],
      "metadata": {
        "id": "Jrf5B6DQyALz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = prepare_model_for_int8_training(model)"
      ],
      "metadata": {
        "id": "82JAEQ6hyCRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = LoraConfig(\n",
        "    r=LORA_R,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    target_modules=TARGET_MODULES,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "id": "rwqr6x1b0eDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, config)"
      ],
      "metadata": {
        "id": "gvoc7Zdk0iEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token_id = 0 "
      ],
      "metadata": {
        "id": "gHVhDuZO0kXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CGxtSYRI0q2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(DATASET_NAME)"
      ],
      "metadata": {
        "id": "kM7H-TxW0mA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOHY9adI0pp6",
        "outputId": "01c83ac0-6040-4216-f618-f2341a84176d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['instruction', 'input', 'output'],\n",
              "        num_rows: 52002\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_val = data[\"train\"].train_test_split(\n",
        "    test_size=VAL_SET_SIZE, shuffle=True, seed=42\n",
        ")\n",
        "train_data = train_val[\"train\"]\n",
        "val_data = train_val[\"test\"]"
      ],
      "metadata": {
        "id": "txApP5d30sba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fKD_xrNp0-Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(data_point):\n",
        "    if data_point[\"input\"]:\n",
        "        return f\"\"\"Abaixo está uma instrução que descreve uma tarefa, emparelhada com uma entrada que fornece mais contexto. Escreva uma resposta que conclua adequadamente a solicitação.\n",
        "### Instruções:\n",
        "{data_point[\"instruction\"]}\n",
        "### Entrada:\n",
        "{data_point[\"input\"]}\n",
        "### Resposta:\n",
        "{data_point[\"output\"]}\"\"\"\n",
        "    else:\n",
        "        return f\"\"\"Abaixo está uma instrução que descreve uma tarefa. Escreva uma resposta que conclua adequadamente a solicitação.\n",
        "### Instruções:\n",
        "{data_point[\"instruction\"]}\n",
        "### Resposta:\n",
        "{data_point[\"output\"]}\"\"\""
      ],
      "metadata": {
        "id": "Q83zi1Kr04li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(prompt):\n",
        "    result = tokenizer(\n",
        "        prompt,\n",
        "        truncation=True,\n",
        "        max_length=CUTOFF_LEN + 1,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    return {\n",
        "        \"input_ids\": result[\"input_ids\"][:-1],\n",
        "        \"attention_mask\": result[\"attention_mask\"][:-1],\n",
        "    }"
      ],
      "metadata": {
        "id": "EL-KolQi1k_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.shuffle().map(lambda x: tokenize(generate_prompt(x)))\n",
        "val_data = val_data.shuffle().map(lambda x: tokenize(generate_prompt(x)))"
      ],
      "metadata": {
        "id": "7xH4uC8z1m_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tgGcSpul2OsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
        "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "        warmup_steps=100,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        fp16=True,\n",
        "        logging_steps=20,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        save_strategy=\"steps\",\n",
        "        eval_steps=200,\n",
        "        save_steps=200,\n",
        "        output_dir=\"lora-alpaca\",\n",
        "        save_total_limit=3,\n",
        "        load_best_model_at_end=True,\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")"
      ],
      "metadata": {
        "id": "QZx93HOV18do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache = False"
      ],
      "metadata": {
        "id": "jipoXa7E2XPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old_state_dict = model.state_dict\n",
        "model.state_dict = (\n",
        "    lambda self, *_, **__: get_peft_model_state_dict(self, old_state_dict())\n",
        ").__get__(model, type(model))"
      ],
      "metadata": {
        "id": "4wh8bWgL2Zte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Tt-7xsmI2gvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"lora-alpaca\")"
      ],
      "metadata": {
        "id": "owDXo0t72izt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}